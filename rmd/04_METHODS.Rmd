# Methods

<!-- The Methods should include detailed text describing any steps or procedures used in producing the data, including full descriptions of the experimental design, data acquisition and any computational processing. See [the detailed section in our submission guidelines](https://www.nature.com/sdata/publish/submission-guidelines#sec-5) for advice on writing a transparent and reproducible methods section. Related methods should be grouped under corresponding subheadings where possible, and methods should be described in enough detail to allow other researchers to interpret and repeat, if required, the full study. Specific data outputs should be explicitly referenced via data citation (see Data Records and Citing Data, below). -->

<!-- Authors should cite previous descriptions of the methods under use, but ideally the method descriptions should be complete enough for others to understand and reproduce the methods and processing steps without referring to associated publications. There is no limit to the length of the Methods section. -->

This section provides a comprehensive description of the steps and procedures used to create the Nominal catch dataset from the different datasets provided by tRFMOs (tuna Regional Fisheries Management Organization).

## Data origin

### Gathering of the data by tRFMOs:

Each tRFMOs has different exchange formats to gather data from fishboats/countries or fisheries. to be continued

### Gathering for Nominal catch dataset:

#### Data call

Fisheries data sets managed by tRFMOs are generally updated on an annual basis according to their respective data submission cycle. Some revisions may also be performed on an irregular basis following corrections and improvements made to historical data. Each year, an official data call is made by the Steering Committee of the FAO Fisheries Resources Monitoring System (FIRMS) to get the most up-to-date versions of the nominal catch data set built by each Secretariat. It takes place around June to ensure that the data will include catches up to the year preceding the call.

#### The CWP Data Exchange Format

For effective amalgamation of multiple datasets, a unified data exchange format has been crafted. Central to this format is the inclusion of:

-   Digital Format Standardization:

The Comma-Separated-Value (CSV) format, adhering to the RFC 4180 standard, has been endorsed.

-   File Encoding Protocol:

Whether in CSV or JSON format, encoding is standardized to UTF-8.

-   Data Dictionary:

A robust data dictionary has been established to guide the structure and semantics of the fisheries data exchange format. This repository, containing terms for column headers and their definitive explanations, is accessible at FDI Terms on GitHub. <https://github.com/fdiwg/fdi-terms> Notably, a specific fisheries term isn't rigidly bound to a single reference code list but varies based on its application context.

In context-specific scenarios, like the Global Tuna Atlas, associations with particular code lists : <https://github.com/fdiwg/fdi-mappings/tree/main/global/firms/gta>

The Global Tuna Atlas has adopted the Generic (measurement-independent) data structure for its operations. \ref table

This section describes the steps and procedures used to create the global nominal catch dataset from the data available within each tRFMO.

### Exchange format & mapping

-   Building of the specific GTA FIRMS fishing fleet code list
-   Mapping with ASFIS/ISSCFG/FIRMS fleets

### Creation of the global dataset

#### Data pre-processing

Before combining the datasets, a pre-processing step is applied to three out of the five datasets to restructure their shape to follow the CWP standards. This restructuring ensures uniformity in the format of the data, facilitating the subsequent integration process. Below is a table listing the links to the datasets provided by each tRFMO:

```{r, warning == FALSE, message = FALSE}
datasets_links_processing <- read_delim(here("inputs/Workflow/datasets_links_processing.csv"),
    delim = ";", escape_double = FALSE, col_types = cols(`Dataset;RFMO;Link to downolad;Pre-processing function;Comments` = col_character()), trim_ws = TRUE)
```

```{r tab.cap = "Datasets and pre-processing functions used in the creation of the final dataset"}
qflextable(datasets_links_processing)
```

```{r results='asis'}
CWP_format <- read_delim(here("inputs/CWP_format.csv"), 
    delim = ";", escape_double = FALSE, trim_ws = TRUE)
qflextable(CWP_format)
```

#### Data Mapping the data

Additionally, to ensure consistency and comparability across datasets, a harmonization process is performed to standardize the code lists for datasets not having be mapped yet. The harmonized datasets allow for seamless data integration and accurate analysis across different tRFMOs. The recap of the mapping can be found in table \ref table

Upon completing the pre-processing and harmonization steps, the global nominal catch dataset is constructed by binding and filtering the data.

1.  Binding of Datasets for each Ocean Region:

All the individual tRFMO datasets, representing different ocean regions, are combined through a data-binding process.

2.  Filtering on Species under Mandate by the tRFMOs:

```{r}

file_url <- "https://raw.githubusercontent.com/fdiwg/fdi-mappings/main/cross-term/codelist_mapping_source_authority_species.csv"
download_link <- paste0("[Download CSV](<", file_url, ">)")

cl_species_level0 <- readr::read_csv(file_url)


```

```{r}

diffstratasnumber <- read.csv("outputs/filtering_species/figures/Diffstratas/Comparison.of.number.of.stratas.between.the.two.datasets.csv")

tidy <- diffstratasnumber[c(1, 3, 4, 5, 6),] %>% rename(" " = X, "Before filtering" = "Before.filtering", "After filtering" = "After.filtering")

qflextable2(tidy, columns_to_color = "Difference")

```

This step involves filtering the data to retain only the information pertaining to species under the mandate of the tRFMOs. The retained species are selected to align with the specific conservation and management goals of each tRFMO.`r SPECIES_ITIS[Aggregate == FALSE, length(unique(TSN))]` are selected.


To be noted, catches of one of the main tuna i.e. Southern Bluefin Tuna is impacted by this treatment. As CCSBT possesses expertise in managing and overseeing data related to this species, their dataset is selected as the primary source for Southern Bluefin Tuna information. The impact is 4.3% of the global value for this species. 

3. Enriching data

To enhance the comprehensibility and usability of the dataset, additional temporal and grouping information is enriched in the data, categorizing species and fishing gear types using mapping of the Data Dictionary.

The code used to perform this workflow is available on: [https://raw.githubusercontent.com/eblondel/geoflow-tunaatlas/master/tunaatlas_scripts/generation/create_global_tuna_atlas_nominal_catch.R](#0){.uri}

## Geoflow workflow and database model

The workflow of creation and the dissemination of the Nominal catch is using the geoflow package <https://github.com/r-geoflow/geoflow>.

Geoflow offers a mechanism that simplifies the coordination and performance of workflows centered on metadata, aligning with the FAIR (Findable, Accessible, Interoperable, and Reusable) principles of data management.

To create the Nominal catch dataset the workflow relies on several steps creating a complete database allowing storage and preserving the integrity of the data. The inputs datasets are stored as well in a googledrive that allows reusing of the processed data. This googledrive storage allows cooperation between the instances. 

For each step, a sheet is associated that recapitulate the inputs, the ouptputs and provide metadata in dublin core format. 

The steps are the following: 

Step 1: Creation of the Database model and loading of shapefiles and codelist.
https://docs.google.com/spreadsheets/d/12zi49c5wd9Nc7N1anv3lCM4f66L-5x3-Xsh6ZGGc-ns/edit#gid=1316104870

Step 2: Loading of the mapping. https://docs.google.com/spreadsheets/d/1xzXgIxjQm81Fg7PCgtdiwhkB9sgtPKk-NByQDRtAGrE/edit#gid=1158322074

Step 3: Loading and Pre-processing of the dataset provided by CCSBT, IATTC, ICCAT, IOTC, WCPFC. (presented earlier see tab)

Step 4: Creation of the Nominal dataset

The Step 8 is the only to display data in zenodo.




